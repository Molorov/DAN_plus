model_params:
    # Model classes to use for each module
    models:
        encoder: 'FCN_Encoder16x16'
        decoder: 'Decoder'
    transfer_learning:
    input_channels: 3  # 1 for grayscale images, 3 for RGB ones (or grayscale as RGB)
    enc_size: 256
    dropout: 0.5
    drop_inside: True

dataset_params:
    name: 'LJK_200'
    level: 'syn_line'
    lan: 'bo'
    dataset_manager: 'OCRDatasetManager'
    dataset_class: 'OCRDataset'
    config:
        load_in_memory: True  # Load all images in CPU memory
        worker_per_gpu: 8
        width_divisor: 16  # Image width will be divided by 16
        height_divisor: 16  # Image height will be divided by 16
        padding_value: 0  # Image padding value
        padding_token: 1000  # Label padding value (None: default value is chosen)
        padding_mode: "br"  # Padding at bottom and right
        charset_mode: "CTC"  # add blank token
        constraints: ["CTC_line", ]  # Padding for CTC requirements if necessary
        exclude_class: [' ']
        normalize: True  # Normalize with mean and variance of training dataset

        preprocessings: [
          {
            type: "to_RGB",
            # if grayscale image, produce RGB one (3 channels with same value) otherwise do nothing
          }
        ]

        #
        synthetic_data:
            mode: "line_hw_to_printed"
            init_proba: 1
            end_proba: 1
            num_steps_proba: 100000 # 1e5
            proba_scheduler_function: 'exponential_scheduler'
            font_dir: 'Kangyur'
            config:
                background_color_default:  [255, 255, 255]
                background_color_eps: 15
                text_color_default: [0, 0, 0]
                text_color_eps: 15
                font_size:
                    cjk: [30, 50]
                    bo: [40, 60]
                color_mode: "RGB"
                padding_left_ratio_min: 0.002
                padding_left_ratio_max: 0.01
                padding_right_ratio_min: 0.002
                padding_right_ratio_max: 0.01
                padding_top_ratio_min: 0.02
                padding_top_ratio_max: 0.2
                padding_bottom_ratio_min: 0.02
                padding_bottom_ratio_max: 0.2
                pixels_per_char_min: 18 # 1.5*16, prevent the line image to be too short
                pixels_per_char_max: 24 # 2*16, prevent the line image to be too long


training_params:
    max_nb_epochs: 500  # max number of epochs for the training
    load_epoch: "last"  # ["best", "last"], to load weights from best epoch or last trained epoch
    interval_save_weights:  # None: keep best and last only
    use_ddp: False  # Use DistributedDataParallel
    use_amp: True  # Enable automatic mix-precision
    batch_size: 16  # mini-batch size per GPU
    optimizers:
        all:
          class: Adam
          args:
            lr: 0.0001
            amsgrad: False

    lr_schedulers:
    eval_on_valid: True  # Whether to eval and logs metrics on validation set during training or not
    eval_on_valid_interval: 2  # Interval (in epochs) to evaluate during training
    focus_metric: "cer"  # Metrics to focus on to determine best epoch
    expected_metric_value: "low"  # ["high", "low"] What is best for the focus metric value
    train_metrics: ["loss_ctc", "cer", "ser"]  # Metrics name for training
    eval_metrics: ["loss_ctc", "cer", "ser"]  # Metrics name for evaluation on validation set during training
    force_cpu: False  # True for debug purposes to run on cpu only
